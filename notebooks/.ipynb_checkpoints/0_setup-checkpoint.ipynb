{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e022ec1-83e7-462c-bf8b-8c85b0374292",
   "metadata": {},
   "source": [
    "# From Delta Lake to Amazon SageMaker\n",
    "\n",
    "## 0 - Connection Set-up\n",
    "\n",
    "In this notebook, we will..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bf389a1-afdb-4750-98f8-d2d1276ff8e9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - openjdk\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.14.0               |   py38h06a4308_0         916 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         916 KB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                               4.13.0-py38h06a4308_0 --> 4.14.0-py38h06a4308_0\n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install openjdk -q -y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e4fc75-88da-409c-8537-2570acbbbd84",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark==3.2.0\n",
      "  Using cached pyspark-3.2.0-py2.py3-none-any.whl\n",
      "Collecting py4j==0.10.9.2\n",
      "  Using cached py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspark==3.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "349cbc14-ed0d-4342-936d-2bb1eeedce88",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting delta-spark==1.1.0\n",
      "  Using cached delta_spark-1.1.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pyspark<3.3.0,>=3.2.0 in /opt/conda/lib/python3.8/site-packages (from delta-spark==1.1.0) (3.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from delta-spark==1.1.0) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=1.0.0->delta-spark==1.1.0) (3.6.0)\n",
      "Requirement already satisfied: py4j==0.10.9.2 in /opt/conda/lib/python3.8/site-packages (from pyspark<3.3.0,>=3.2.0->delta-spark==1.1.0) (0.10.9.2)\n",
      "Installing collected packages: delta-spark\n",
      "Successfully installed delta-spark-1.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install delta-spark==1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "007f26e2-8ac1-4944-827f-92308cf7e585",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.8/site-packages (2.105.0)\n",
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.107.0.tar.gz (568 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m568.4/568.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: attrs<22,>=20.3.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (20.3.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.20.21 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.24.57)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.19.5)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (3.20.1)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (4.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (21.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.1.5)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.2.8)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.57 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (1.27.57)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->sagemaker) (3.0.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.8/site-packages (from pandas->sagemaker) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pox>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.0)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (1.6.6.4)\n",
      "Requirement already satisfied: dill>=0.3.4 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.70.12.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.57->boto3<2.0,>=1.20.21->sagemaker) (1.26.9)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.107.0-py2.py3-none-any.whl size=784128 sha256=9a38f98faaea9990c23fac405e2437881e599d4273eb2e989c98a66f0505a822\n",
      "  Stored in directory: /root/.cache/pip/wheels/49/84/d6/be7707e36d08706ead27ebc97a732eff8b739f05b1387bf8aa\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: sagemaker\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.105.0\n",
      "    Uninstalling sagemaker-2.105.0:\n",
      "      Successfully uninstalled sagemaker-2.105.0\n",
      "Successfully installed sagemaker-2.107.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U \"sagemaker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea4844f2-a3a6-4c1e-bab1-38f62a2eb0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.107.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ff187ee-e094-4284-bac9-9572df0d4b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pyspark and build Spark session\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3747182b-0676-4056-b003-24975a239eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packages: io.delta:delta-core_2.12:1.1.0,org.apache.hadoop:hadoop-aws:3.2.2\n"
     ]
    }
   ],
   "source": [
    "# Build list of packages entries using Maven coordinates (groupId:artifactId:version)\n",
    "pkg_list = []\n",
    "pkg_list.append(\"io.delta:delta-core_2.12:1.1.0\")\n",
    "pkg_list.append(\"org.apache.hadoop:hadoop-aws:3.2.2\")\n",
    "\n",
    "packages=(\",\".join(pkg_list))\n",
    "print('packages: '+packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07721cbf-eaab-4bad-951d-db3d194fbc69",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.aws.credentials.provider\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/conda/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/conda/lib/python3.8/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-d319fd07-ddfc-4e3d-ae76-ab7af30c664d;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;1.1.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.8 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.2.2 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.563 in central\n",
      ":: resolution report :: resolve 717ms :: artifacts dl 68ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.563 from central in [default]\n",
      "\tio.delta#delta-core_2.12;1.1.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.8 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.2.2 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-d319fd07-ddfc-4e3d-ae76-ab7af30c664d\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 5 already retrieved (0kB/27ms)\n",
      "22/08/31 11:05:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.2.0\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Spark via builder\n",
    "# Note: we use the `ContainerCredentialsProvider` to give us access to underlying IAM role permissions\n",
    "\n",
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .appName(\"PySparkApp\") \n",
    "    .config(\"spark.jars.packages\", packages) \n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \n",
    "    .config(\"fs.s3a.aws.credentials.provider\",'com.amazonaws.auth.ContainerCredentialsProvider') \n",
    "    .getOrCreate())\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "print('Spark version: '+str(sc.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61395998-70f2-4360-adb9-38701c55849d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default bucket: sagemaker-eu-west-1-889960878219\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# S3 bucket for saving processing job outputs\n",
    "sm_session = sagemaker.Session()\n",
    "bucket = sm_session.default_bucket()\n",
    "region = sm_session.boto_region_name\n",
    "\n",
    "sm_client = boto3.client('sagemaker')\n",
    "iam_role = sagemaker.get_execution_role()\n",
    "\n",
    "print('Default bucket: '+bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fdd386f-bf95-452b-86f3-b1052bb4b255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-eu-west-1-889960878219/delta_to_sagemaker/raw_csv/BostonHousing.csv'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "local_basename = 'BostonHousing.csv'\n",
    "local_file = './data/' + local_basename\n",
    "upload_s3_uri = f's3://{bucket}/delta_to_sagemaker/raw_csv'\n",
    "\n",
    "S3Uploader.upload(local_file, upload_s3_uri, sagemaker_session=sm_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee90e5ec-3e19-4d36-bd6c-6069cd6af219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3a://sagemaker-eu-west-1-889960878219/delta_to_sagemaker/raw_csv/BostonHousing.csv\n"
     ]
    }
   ],
   "source": [
    "# Load raw data from S3 location\n",
    "\n",
    "s3_raw_csv = f's3://{bucket}/delta_to_sagemaker/raw_csv/BostonHousing.csv'\n",
    "s3a_raw_csv = s3_raw_csv.replace('s3:','s3a:')\n",
    "\n",
    "print(s3a_raw_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "246f3f4e-695f-430b-a906-0d37d36e8b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.1 ms, sys: 226 µs, total: 3.33 ms\n",
      "Wall time: 902 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "housing_df = spark.read.csv(s3a_raw_csv, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6281146-92d2-4773-8608-5bfe953feb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('crim', 'string'),\n",
       " ('zn', 'string'),\n",
       " ('indus', 'string'),\n",
       " ('chas', 'string'),\n",
       " ('nox', 'string'),\n",
       " ('rm', 'string'),\n",
       " ('age', 'string'),\n",
       " ('dis', 'string'),\n",
       " ('rad', 'string'),\n",
       " ('tax', 'string'),\n",
       " ('ptratio', 'string'),\n",
       " ('b', 'string'),\n",
       " ('lstat', 'string'),\n",
       " ('medv', 'string')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Rows: '+str(housing_df.count()))\n",
    "housing_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0019150-16fa-42f8-b0d0-cddc37ef46ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio|     b|lstat|medv|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "|0.00632|  18| 2.31|   0|0.538|6.575|65.2|  4.09|  1|296|   15.3| 396.9| 4.98|  24|\n",
      "|0.02731|   0| 7.07|   0|0.469|6.421|78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|\n",
      "|0.02729|   0| 7.07|   0|0.469|7.185|61.1|4.9671|  2|242|   17.8|392.83| 4.03|34.7|\n",
      "|0.03237|   0| 2.18|   0|0.458|6.998|45.8|6.0622|  3|222|   18.7|394.63| 2.94|33.4|\n",
      "|0.06905|   0| 2.18|   0|0.458|7.147|54.2|6.0622|  3|222|   18.7| 396.9| 5.33|36.2|\n",
      "|0.02985|   0| 2.18|   0|0.458| 6.43|58.7|6.0622|  3|222|   18.7|394.12| 5.21|28.7|\n",
      "|0.08829|12.5| 7.87|   0|0.524|6.012|66.6|5.5605|  5|311|   15.2| 395.6|12.43|22.9|\n",
      "|0.14455|12.5| 7.87|   0|0.524|6.172|96.1|5.9505|  5|311|   15.2| 396.9|19.15|27.1|\n",
      "|0.21124|12.5| 7.87|   0|0.524|5.631| 100|6.0821|  5|311|   15.2|386.63|29.93|16.5|\n",
      "|0.17004|12.5| 7.87|   0|0.524|6.004|85.9|6.5921|  5|311|   15.2|386.71| 17.1|18.9|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "housing_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96ae33f1-7a5a-4e15-846a-cba1f0a4f930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3a://sagemaker-eu-west-1-889960878219/delta_to_sagemaker/delta_format/\n"
     ]
    }
   ],
   "source": [
    "# Write dataframe to Delta Table location using 's3a' protocol\n",
    "\n",
    "s3_delta_table_uri=f's3://{bucket}/delta_to_sagemaker/delta_format/'\n",
    "s3a_delta_table_uri=s3_delta_table_uri.replace('s3:','s3a:')\n",
    "\n",
    "print(s3a_delta_table_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d232e21b-ca2e-40cd-94b6-6c92db85e691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "housing_df.write.format(\"delta\").mode(\"overwrite\").save(s3a_delta_table_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b02425-a677-4e1f-9208-377a4113eaab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/sagemaker-data-science-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
